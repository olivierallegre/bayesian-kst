{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ef1ab1",
   "metadata": {},
   "source": [
    "# Comparison between pyBKT and BKT with pyAgrum\n",
    "In this notebook, we want to make sure that the way we implement BKT with pyAgrum corresponds to the values obtained by pyBKT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b7dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/olivier/PycharmProjects/bayesian-kst/\")  # for mac\n",
    "\n",
    "import pyAgrum as gum\n",
    "from kgraph.expert_layer.domain import Domain\n",
    "from kgraph.expert_layer.knowledge_components import KnowledgeComponent\n",
    "from kgraph.expert_layer.link import Link\n",
    "from kgraph.resources_layer.exercise import Exercise\n",
    "from kgraph.learner_layer.answer import LearnerAnswer\n",
    "from kgraph.learner_layer.learner import Learner\n",
    "from kgraph.learner_layer.learner_pool import LearnerPool\n",
    "from kgraph.helpers.truthtable import truthtable\n",
    "from math import floor\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "import pyAgrum.lib.dynamicBN as gdyn\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def get_strongest_folds(full, axis=\"user_id\", nb_folds=5):\n",
    "    all_elements = full[axis].unique()\n",
    "\n",
    "    kfold = KFold(nb_folds, shuffle=True)\n",
    "    folds = []\n",
    "    for i, (train, test) in enumerate(kfold.split(all_elements)):\n",
    "        list_of_test_ids = []\n",
    "        for element_id in test:\n",
    "            list_of_test_ids += list(full.query(f'{axis} == {all_elements[element_id]}').index)\n",
    "        folds.append(np.array(list_of_test_ids))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def mae(true_vals, pred_vals):\n",
    "    \"\"\" Calculates the mean absolute error. \"\"\"\n",
    "    return np.mean(np.abs(true_vals - pred_vals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20d0eb",
   "metadata": {},
   "source": [
    "## Define the domain knowledge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2312231",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we define the KCs\n",
    "\n",
    "KC_A = KnowledgeComponent(55365, \"Déterminer l'appartenance d'un nombre réel à un intervalle fini\")\n",
    "KC_B = KnowledgeComponent(55363, \"Déterminer l'appartenance d'un nombre réel à un intervalle infini\")\n",
    "KC_C = KnowledgeComponent(55364, \"Déterminer l'appartenance d'un nombre réel à un intervalle simple\")\n",
    "KC_D = KnowledgeComponent(50988, \"Déterminer l'appartenance d'un nombre réel à une intersection d'intervalles de R\")\n",
    "KC_E = KnowledgeComponent(50989, \"Déterminer l'appartenance d'un nombre réel à une réunion d'intervalles de R\")\n",
    "\n",
    "A_2_C = Link(source=KC_A, target=KC_C)\n",
    "B_2_C = Link(source=KC_B, target=KC_C)\n",
    "C_2_D = Link(source=KC_C, target=KC_D)\n",
    "C_2_E = Link(source=KC_C, target=KC_E)\n",
    "domain = Domain([KC_A, KC_B, KC_C, KC_D, KC_E], [A_2_C, B_2_C, C_2_D, C_2_E])\n",
    "\n",
    "params = {\"slip\": .01, \"guess\":.01}\n",
    "\n",
    "# there are 5 exercises corresponding to KC A\n",
    "ex_A_1 = Exercise(237957, KC_A, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_A_2 = Exercise(237958, KC_A, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_A_3 = Exercise(237959, KC_A, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_A_4 = Exercise(237960, KC_A, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_A_5 = Exercise(237961, KC_A, \"qcm\", ex_content=\"\", params=params)\n",
    "\n",
    "# there are also 5 exercises corresponding to KC B\n",
    "ex_B_1 = Exercise(237947, KC_B, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_B_2 = Exercise(237948, KC_B, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_B_3 = Exercise(237949, KC_B, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_B_4 = Exercise(237950, KC_B, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_B_5 = Exercise(237951, KC_B, \"qcm\", ex_content=\"\", params=params)\n",
    "\n",
    "ex_C_1 = Exercise(237952, KC_C, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_C_2 = Exercise(237953, KC_C, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_C_3 = Exercise(237954, KC_C, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_C_4 = Exercise(237955, KC_C, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_C_5 = Exercise(237956, KC_C, \"qcm\", ex_content=\"\", params=params)\n",
    "\n",
    "\n",
    "ex_D_1 = Exercise(225183, KC_D, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_D_2 = Exercise(225184, KC_D, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_D_3 = Exercise(225185, KC_D, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_D_4 = Exercise(225186, KC_D, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_D_5 = Exercise(225187, KC_D, \"qcm\", ex_content=\"\", params=params)\n",
    "\n",
    "ex_E_1 = Exercise(225165, KC_E, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_E_2 = Exercise(225166, KC_E, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_E_3 = Exercise(225167, KC_E, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_E_4 = Exercise(225168, KC_E, \"qcm\", ex_content=\"\", params=params)\n",
    "ex_E_5 = Exercise(225169, KC_E, \"qcm\", ex_content=\"\", params=params)\n",
    "\n",
    "def get_KC_from_exercise_id(exercise_id):\n",
    "    if exercise_id in range(237957, 237962):\n",
    "        return KC_A\n",
    "    elif exercise_id in range(237947, 237952):\n",
    "        return KC_B\n",
    "    elif exercise_id in range(237952, 237957):\n",
    "        return KC_C\n",
    "    elif exercise_id in range(225183, 225188):\n",
    "        return KC_D\n",
    "    else:\n",
    "        return KC_E\n",
    "    \n",
    "learner_pool = LearnerPool(domain, {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e948db0a",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e9c3a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         idx  doc_id  exercise_id  evaluation_id  success  user_id  \\\n",
      "0          1   50988       225183      109276367        0   757204   \n",
      "1          2   50988       225183      109293461        1  2052585   \n",
      "2          3   50988       225183      109293517        1  2052585   \n",
      "3          4   50988       225183      109293574        1  2052585   \n",
      "4          5   50988       225183      109307385        1  1896564   \n",
      "...      ...     ...          ...            ...      ...      ...   \n",
      "42478  42479   55365       237961      151659716        1  1278392   \n",
      "42479  42480   55365       237961      151664581        1  3926123   \n",
      "42480  42481   55365       237961      151667070        1  3275043   \n",
      "42481  42482   55365       237961      151667191        1  3275043   \n",
      "42482  42483   55365       237961      151669835        1  1699544   \n",
      "\n",
      "                 createdAt  \n",
      "0      2019-08-12 12:57:49  \n",
      "1      2019-08-12 19:18:03  \n",
      "2      2019-08-12 19:20:45  \n",
      "3      2019-08-12 19:23:40  \n",
      "4      2019-08-13 11:16:49  \n",
      "...                    ...  \n",
      "42478  2021-09-15 15:40:56  \n",
      "42479  2021-09-15 17:48:58  \n",
      "42480  2021-09-15 18:53:20  \n",
      "42481  2021-09-15 18:56:27  \n",
      "42482  2021-09-15 20:34:52  \n",
      "\n",
      "[42483 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"5_KCs_example_data.csv\")\n",
    "\n",
    "print(df)\n",
    "\n",
    "folds = get_strongest_folds(df, \"user_id\", 2)\n",
    "test_ids = folds[0]\n",
    "\n",
    "train_ids = list(set(list(df.index.values)) - set(test_ids))\n",
    "\n",
    "df_train = df[df.index.isin(train_ids)]\n",
    "df_test = df[df.index.isin(test_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dc34e",
   "metadata": {},
   "source": [
    "## Learn parameters with pyBKT\n",
    "We learn the parameters of the bayesian network with pyBKT (EM algorithm) on the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c13c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyBKT.models import Model\n",
    "\n",
    "# Initialize the model with an optional seed\n",
    "model = Model(seed = 42, num_fits = 1)\n",
    "defaults = {'order_id': 'idx', 'skill_name': 'doc_id', 'correct': 'success'}\n",
    "\n",
    "model.fit(data = df_train, defaults = defaults)\n",
    "\n",
    "for kc in learner_pool.get_knowledge_components():\n",
    "    learner_pool.set_learn(kc, model.params().loc[f'{kc.id}', 'learns', 'default'].value)\n",
    "    learner_pool.set_prior(kc, model.params().loc[f'{kc.id}', 'prior', 'default'].value)\n",
    "    learner_pool.set_slip(kc, model.params().loc[f'{kc.id}', 'slips', 'default'].value)\n",
    "    learner_pool.set_guess(kc, model.params().loc[f'{kc.id}', 'guesses', 'default'].value)\n",
    "    learner_pool.set_forget(kc, model.params().loc[f'{kc.id}', 'forgets', 'default'].value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cfebe2",
   "metadata": {},
   "source": [
    "## Check prediction performance of pyBKT model\n",
    "We then check how the prediction is performed with pyBKT and the learned parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdd1acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.7375482534601262\n",
      "AUC 0.7018746632618859\n",
      "MAE 0.3626989069046264\n"
     ]
    }
   ],
   "source": [
    "print('ACC', model.evaluate(data = df_test, metric = 'accuracy'))\n",
    "print('AUC', model.evaluate(data = df_test, metric = 'auc'))\n",
    "print('MAE', model.evaluate(data = df_test, metric = mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62e004",
   "metadata": {},
   "source": [
    "## Check prediction performance of BKT with pyAgrum library\n",
    "We setup the same process for BKT with pyAgrum, with parameters computed thanks to pyBKT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4cc2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bkt_net(learner, kc, n_eval):\n",
    "    bkt_net = gum.BayesNet('BKT')\n",
    "    learn = learner.learner_pool.get_learn(kc)\n",
    "    prior = learner.learner_pool.get_prior(kc)\n",
    "    guess = learner.learner_pool.get_guess(kc)\n",
    "    slip = learner.learner_pool.get_slip(kc)\n",
    "    forget = learner.learner_pool.get_forget(kc)\n",
    "    bkt_net.add(gum.LabelizedVariable(f\"({kc.name})0\", '', 2))\n",
    "    bkt_net.cpt(f\"({kc.name})0\").fillWith([1-prior, prior])\n",
    "    for i in range(1, n_eval+1):\n",
    "        bkt_net.add(gum.LabelizedVariable(f\"({kc.name}){i}\", '', 2))\n",
    "        bkt_net.add(gum.LabelizedVariable(f\"eval({kc.name}){i}\", '', 2))\n",
    "        bkt_net.addArc(*(f\"({kc.name}){i}\", f\"eval({kc.name}){i}\"))\n",
    "        bkt_net.cpt(f\"eval({kc.name}){i}\")[{f\"({kc.name}){i}\": False}] = [1-guess, guess]\n",
    "        bkt_net.cpt(f\"eval({kc.name}){i}\")[{f\"({kc.name}){i}\": True}] = [slip, 1-slip]\n",
    "        bkt_net.addArc(*(f\"({kc.name}){i-1}\", f\"({kc.name}){i}\"))\n",
    "        bkt_net.cpt(f\"({kc.name}){i}\")[{f\"({kc.name}){i-1}\": False}] = [1-learn, learn]\n",
    "        bkt_net.cpt(f\"({kc.name}){i}\")[{f\"({kc.name}){i-1}\": True}] = [forget, 1-forget]\n",
    "\n",
    "    return bkt_net\n",
    "\n",
    "def evaluate_learner_bkt(learner, evaluations):\n",
    "    n_eval = len(evaluations)\n",
    "    evaluated_kc = evaluations[0][0]  # we suppose that evaluated_kc is the same for all evaluations\n",
    "    floor_idx = 0\n",
    "    expected_values = []\n",
    "    predicted_values = []\n",
    "    for i in range(floor_idx, n_eval):\n",
    "        bn = get_bkt_net(learner, evaluated_kc, i+1)\n",
    "        ie=gum.LazyPropagation(bn)\n",
    "        ie.setEvidence({f\"eval({evaluations[j][0].name}){j+1}\": evaluations[j][1] for j in range(i)})\n",
    "        ie.makeInference()\n",
    "        predicted_values.append(ie.posterior(f\"eval({evaluations[i][0].name}){i+1}\")[:][1])\n",
    "        expected_values.append(evaluations[i][1])\n",
    "\n",
    "    return (expected_values, predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b13da5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:33<00:00,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.7375482534601262\n",
      "AUC 0.702061189270409\n",
      "MAE 0.3638476046491296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Score with pyAgrum\n",
    "\n",
    "expected_values = []\n",
    "predicted_values = []\n",
    "\n",
    "for kc_id in tqdm.tqdm(df_test[\"doc_id\"].unique()):\n",
    "    kc_evals = df_test[df_test[\"doc_id\"] == kc_id]\n",
    "    for learner_id in kc_evals[\"user_id\"].unique():\n",
    "        learner = Learner(learner_id, learner_pool)\n",
    "        learner_evals = kc_evals[kc_evals[\"user_id\"] == learner_id]\n",
    "        answers = [[get_KC_from_exercise_id(row[\"exercise_id\"]), row[\"success\"]] \n",
    "                   for i, row in learner_evals.iterrows()]\n",
    "        n_eval = len(answers)\n",
    "        floor_idx = 0\n",
    "        exp_vals, pred_vals = evaluate_learner_bkt(learner, answers)\n",
    "        predicted_values = np.concatenate((predicted_values, pred_vals))\n",
    "        expected_values = np.concatenate((expected_values, exp_vals))\n",
    "\n",
    "print('ACC', accuracy_score(expected_values, [1 if x>.5 else 0 for x in predicted_values]))\n",
    "print('AUC', roc_auc_score(expected_values, predicted_values))\n",
    "print('MAE', mae(expected_values, predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9cb0a4",
   "metadata": {},
   "source": [
    "Conclusion: same results but a way longer compute time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
